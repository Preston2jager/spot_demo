# ===== =================== =====
# ===== RMIT Spot control class =====
# ===== =================== =====
import os
import time
import math
import cv2
from typing import Optional
import numpy as np
# ===== Tracker and Streamer =====
from cls_rmit_spot_tracker import SpotTracker
from cls_rmit_spot_stream import SpotStreamer
# ===== BostonDynamic APIs =====
import bosdyn.client
from bosdyn.api import manipulation_api_pb2
from bosdyn.api import geometry_pb2
from bosdyn.api.graph_nav import graph_nav_pb2, nav_pb2, map_pb2
from bosdyn.client.graph_nav import GraphNavClient
from bosdyn.client.image import build_image_request, ImageClient
from bosdyn.client.lease import LeaseClient, LeaseKeepAlive
from bosdyn.client.manipulation_api_client import ManipulationApiClient
from bosdyn.client.recording import GraphNavRecordingServiceClient
from bosdyn.client.robot_command import RobotCommandClient, RobotCommandBuilder, blocking_stand
from bosdyn.client.robot_state import RobotStateClient
from bosdyn.client.frame_helpers import (
    GRAV_ALIGNED_BODY_FRAME_NAME,
    HAND_FRAME_NAME,
    ODOM_FRAME_NAME,     
    BODY_FRAME_NAME,   
    get_a_tform_b,
    get_se2_a_tform_b,
    math_helpers
)

class SpotAgent:

    # region  Private APIs: Initialisation

    @SpotTracker("Spot agent initialisation", exit_on_fail=True)
    def __init__(
        self,
        *,
        client_name: str = "SpotAgent",
        keep_alive_period_sec: float = 2.0,
        force_lease: bool = True,
        stream: bool = False,
        navigation: bool = False
    ):
        self.hostname = "192.168.80.3"
        self.username = "user"
        self.password = "myjujz7e2prj"
        self.stream_state = stream
        self.navigation_state = navigation
        self.client_name = client_name
        self.keep_alive_period_sec = keep_alive_period_sec
        self.sdk: Optional[bosdyn.client.Sdk] = None
        self.robot: Optional[bosdyn.client.Robot] = None
        self.lease_client: Optional[LeaseClient] = None
        self.cmd_client: Optional[RobotCommandClient] = None
        self.img_client: Optional[ImageClient] = None
        self.state_client: Optional[RobotStateClient] = None
        self.graph_nav_client: Optional[GraphNavClient] = None
        self.recording_client: Optional[GraphNavRecordingServiceClient] = None
        self._lease_keepalive: Optional[LeaseKeepAlive] = None
        self.force_lease = force_lease  

    @SpotTracker("Spot agent services startup", exit_on_fail=True)
    def __enter__(self):
        #assert self.robot is not None, "Robot must be initialized"
        self._auto_login(self.username, self.password)
        self._get_lease(force=self.force_lease)
        _ = self.robot.ensure_client(RobotCommandClient.default_service_name)
        self._clear_behavior_faults()
        self._power_on_and_stand()
        with SpotTracker("Streming startup", exit_on_fail=False):
            if self.stream_state:
                streamer = SpotStreamer(self.robot)
                streamer.start()
        with SpotTracker("Navigation startup", exit_on_fail=False):  
            if self.navigation_state:
                self.graph = self.get_current_graph()
                if not self.graph:
                    self.graph = self.upload_graph_and_snapshots("./Maps/amp2")
                    # List of all maps
                    # ./Maps/lv12_office 
                if not self.graph:
                    print("[No graph available and failed to upload. Check connection and graph path.")
                    return
                if not self.initialize_graphnav_to_fiducial():
                    print("Failed to initialize GraphNav. Check connection and fiducial setup.")
                    return
        return self

    def __exit__(self, *args):
        self._shutdown()

    # endregion

    # region  Private APIs: Spot admin

    @SpotTracker("Login and Time Sync")
    def _auto_login(self, username: str, password: str):
        self.sdk = bosdyn.client.create_standard_sdk(self.client_name)
        self.robot = self.sdk.create_robot(self.hostname)
        self.robot.authenticate(username, password)
        self.robot.time_sync.start() # type: ignore
        sync_success = False
        for i in range(3):
            try:
                self.robot.time_sync.wait_for_sync(timeout_sec=5.0) # type: ignore
                sync_success = True
                break
            except Exception:
                print(f"Time sync failed, attemp ({i+1}/3)...")
                time.sleep(1)
        if not sync_success:
            raise RuntimeError("Can not establish time sync with the robot. Please check the connection and try again.")
        self.lease_client = self.robot.ensure_client(LeaseClient.default_service_name)
        self.cmd_client = self.robot.ensure_client(RobotCommandClient.default_service_name)
        self.img_client = self.robot.ensure_client(ImageClient.default_service_name)
        self.state_client = self.robot.ensure_client(RobotStateClient.default_service_name)
        self.graph_nav_client = self.robot.ensure_client(GraphNavClient.default_service_name)
        self.recording_client = self.robot.ensure_client(GraphNavRecordingServiceClient.default_service_name)
        self.manip_client = self.robot.ensure_client(ManipulationApiClient.default_service_name)

    @SpotTracker("Take Spot lease", exit_on_fail=True)
    def _get_lease(self, force: bool = False):
        if self._lease_keepalive:
            self._lease_keepalive.shutdown()
        if force:
            try:
                self.lease_client.take() # type: ignore
            except Exception as e:
                print(f"[Lease] âš ï¸ Fail to get the lease: {e}")
        self._lease_keepalive = LeaseKeepAlive(self.lease_client, must_acquire=True, return_at_exit=True)
    
    @SpotTracker("Power on and Stand", exit_on_fail=True)
    def _power_on_and_stand(self, arm = False):
        if not self.robot.is_powered_on(): # type: ignore
            self.robot.power_on(timeout_sec=20) # type: ignore
        blocking_stand(self.cmd_client, timeout_sec=10)
        if arm:
            self._arm_out()

    @SpotTracker("Shutdown", exit_on_fail=False)
    def _shutdown(self):
        if self._lease_keepalive:
            self._lease_keepalive.shutdown()
    
    @SpotTracker("Clear Behavior Faults", exit_on_fail=False)
    def _clear_behavior_faults(self) -> bool:
        if self.state_client is None or self.cmd_client is None:
            print("Clients not initialised, cannot check or clear faults.")
            return False
        try:
            state = self.state_client.get_robot_state()
            faults = state.behavior_fault_state.faults # type: ignore
            if not faults:
                print("No behavior faults detected. Spot is ready to go")
                return True
            print(f"{len(faults)} faults, attempting to clear...")
            for fault in faults:
                print(f"  -> ğŸ›‘ æ•…éšœ ID: {fault.behavior_fault_id}")
                print(f"  -> ğŸ“ æ•…éšœåŸå› : {fault.cause}")
                self.cmd_client.clear_behavior_fault(behavior_fault_id=fault.behavior_fault_id)
                time.sleep(0.5)
            time.sleep(1.0)
            new_state = self.state_client.get_robot_state()
            if not new_state.behavior_fault_state.faults: # type: ignore
                print(" ğŸ‰ æ‰€æœ‰è¡Œä¸ºæ•…éšœå·²æˆåŠŸæ¸…é™¤ï¼")
                return True
            else:
                print(f" There are still {len(new_state.behavior_fault_state.faults)} faults remaining.") # type: ignore
                print("Use tablet to investigate and clear them manually before retrying.")
                return False
        except Exception as e:
            print(f"Error: {e}")
            return False    

    # endregion
    
    # region Private APIs: Arm actions
    
    @SpotTracker("Arm Out (Absolute)", exit_on_fail=False)
    def _arm_out(self):
        if self.cmd_client is None:
            raise RuntimeError("Clients not initialised.")
        try:
            # ç»å¯¹åæ ‡ç³»ï¼šåŸç‚¹åœ¨æœºå™¨äººèº«ä½“ä¸­å¿ƒï¼ŒXæŒ‡å‘å‰æ–¹ï¼ŒYæŒ‡å‘å·¦ä¾§ï¼ŒZæŒ‡å‘ä¸Šæ–¹
            root_frame = GRAV_ALIGNED_BODY_FRAME_NAME
            
            # è®¾ç½®ç»å¯¹ç›®æ ‡ä½ç½®ï¼š
            target_x = 0.80   # è·ç¦»æœºå™¨äººèº«ä½“ä¸­å¿ƒæ­£å‰æ–¹ 0.8 ç±³
            target_y = 0.0    # å·¦å³å±…ä¸­
            target_z = -0.15  # è·ç¦»èº«ä½“ä¸­å¿ƒé«˜åº¦å‘ä¸‹ 0.15 ç±³
            
            # è®¾ç½®ç»å¯¹æ—‹è½¬ï¼šå‘ä¸‹ä½å¤´ 25 åº¦
            pitch_rad = 25.0 * math.pi / 180.0 
            q = math_helpers.Quat.from_pitch(pitch_rad)
            
            # æ„å»ºå¹¶å‘é€æ‰‹è‡‚ç§»åŠ¨æŒ‡ä»¤
            arm_cmd = RobotCommandBuilder.arm_pose_command(
                target_x, target_y, target_z,
                q.w, q.x, q.y, q.z, 
                root_frame, 
                2.0  # ç»™äºˆ 2.0 ç§’çš„æ—¶é—´è®©æ‰‹è‡‚å¹³æ»‘ç§»åŠ¨åˆ°æŒ‡å®šä½ç½®
            )
            self.cmd_client.robot_command(arm_cmd)
            time.sleep(2.0) # ç­‰å¾…æ‰‹è‡‚åˆ°ä½
            
            # æ‰“å¼€æŠ“æ‰‹å‡†å¤‡æ‰«æ
            self.cmd_client.robot_command(RobotCommandBuilder.claw_gripper_open_command())
            time.sleep(0.5)
            print("Arm is out and ready (Absolute pose).")
            
        except Exception as e:
            print(f"Arm out failed: {e}")

    @SpotTracker("Arm Release and Stow", exit_on_fail=False)
    def _arm_release(self, bin=False):
        """
        æŠ“å–æˆåŠŸåè°ƒç”¨ï¼šå°†ç‰©å“ç§»åŠ¨åˆ°ä½å¤„ -> æ¾å¼€æŠ“æ‰‹ -> æ”¶èµ·æ‰‹è‡‚
        """
        if self.cmd_client is None:
            raise RuntimeError("Clients not initialised.")
        try:
            root_frame = GRAV_ALIGNED_BODY_FRAME_NAME
            print("Moving arm to a lower position to release...")
            if bin:
                target_x = 0.8   #
                target_y = 0.0    # å·¦å³å±…ä¸­
                target_z = 0.2  # å°½å¯èƒ½ä½çš„ä½ç½® (åŸºäºèº«ä½“ä¸­å¿ƒå‘ä¸‹ 0.4 ç±³)
                pitch_rad = 60.0 * math.pi / 180.0 
            else:
                target_x = 1   # èº«ä½“æ­£å‰æ–¹ 0.85 ç±³
                target_y = 0.0    # å·¦å³å±…ä¸­
                target_z = -0.20  # å°½å¯èƒ½ä½çš„ä½ç½® (åŸºäºèº«ä½“ä¸­å¿ƒå‘ä¸‹ 0.4 ç±³)
                pitch_rad = 60.0 * math.pi / 180.0 
            q = math_helpers.Quat.from_pitch(pitch_rad)
            lower_cmd = RobotCommandBuilder.arm_pose_command(
                target_x, target_y, target_z,
                q.w, q.x, q.y, q.z, 
                root_frame, 
                1.0  # å› ä¸ºæ‰‹ä¸Šæ‹¿ç€ä¸œè¥¿ï¼Œç»™ 2.5 ç§’æ—¶é—´è®©ä¸‹é™åŠ¨ä½œæ›´å¹³æ»‘
            )
            self.cmd_client.robot_command(lower_cmd)
            time.sleep(1.0) # å¿…é¡»ç­‰å¾…ç§»åŠ¨å®Œæˆï¼Œå¦åˆ™å¯èƒ½ä¼šåœ¨åŠç©ºä¸­ç›´æ¥æ‰”æ‰
            print("Releasing object...")
            self.cmd_client.robot_command(RobotCommandBuilder.claw_gripper_open_command())
            time.sleep(1.0) # ç»™ç‰©å“æ‰è½çš„æ—¶é—´
            print("Stowing arm...")
            stow_cmd = RobotCommandBuilder.arm_stow_command()
            self.cmd_client.robot_command(stow_cmd)
            time.sleep(0.5) # ç­‰å¾… stow æŒ‡ä»¤å¼€å§‹æ‰§è¡Œ
            print("Object released and arm stowed.")
        except Exception as e:
            print(f"Arm release failed: {e}")
    
    @SpotTracker("Arm In", exit_on_fail=False)
    def _arm_in(self):
        if self.cmd_client is None:
            raise RuntimeError("Clients not initialised.")
        try:
            self.cmd_client.robot_command(RobotCommandBuilder.claw_gripper_close_command())
            stow_cmd = RobotCommandBuilder.arm_stow_command()
            self.cmd_client.robot_command(stow_cmd)
            print("Arm stowing...")
        except Exception as e:
            print(f"Arm stow failed: {e}")    

    # endregion
    
    # region Public APIs: Manipulation & Vision Logic

    @SpotTracker("Scanning", exit_on_fail=False)
    def find_targetyolo(self, yolo_detector):
        print("Scanning for targets")
        camera_sources = [
            "hand_color_image"
        ]
        image_requests = [build_image_request(src) for src in camera_sources]
        try:
            image_responses = self.img_client.get_image(image_requests) # type: ignore
        except Exception as e:
            print(f"Failed to accquire images: {e}")
            return None
        images_to_detect = {}
        for img_resp in image_responses: # type: ignore
            cam_name = img_resp.source.name # type: ignore
            img_data = np.frombuffer(img_resp.shot.image.data, dtype=np.uint8) # type: ignore
            cv_img = cv2.imdecode(img_data, cv2.IMREAD_COLOR)
            if cv_img is not None:
                images_to_detect[cam_name] = cv_img
        if not images_to_detect:
            return None
        detections = yolo_detector.detect_targets_in_batch(images_to_detect, conf=0.1)
        if detections:
            top_hit = detections[0]
            print(f" Best target is from [{top_hit['camera']}]: "
                  f"{top_hit['class']} (Conf: {top_hit['conf']:.2f})")
            return top_hit
        return None
    
    @SpotTracker("Quick scanning", exit_on_fail=False)
    def quick_detect(self, yolo_detector):
        print("Scanning for targets")
        camera_sources = [
            "frontleft_fisheye_image", 
            "frontright_fisheye_image", 
            "left_fisheye_image", 
            "right_fisheye_image", 
            "back_fisheye_image",
            "hand_color_image"
        ]
        image_requests = [build_image_request(src) for src in camera_sources]
        try:
            image_responses = self.img_client.get_image(image_requests) # type: ignore
        except Exception as e:
            print(f"Failed to accquire images: {e}")
            return None
            
        images_to_detect = {}
        for img_resp in image_responses: # type: ignore
            cam_name = img_resp.source.name # type: ignore
            img_data = np.frombuffer(img_resp.shot.image.data, dtype=np.uint8) # type: ignore
            cv_img = cv2.imdecode(img_data, cv2.IMREAD_COLOR)
            if cv_img is not None:
                images_to_detect[cam_name] = cv_img
                
        if not images_to_detect:
            return None
            
        # è°ƒç”¨ä½ å®šä¹‰çš„æ£€æµ‹å™¨
        detections = yolo_detector.detect_targets_in_batch(images_to_detect, conf=0.1)
        
        if detections:
            top_hit = detections[0]
            print(f" Best target is from [{top_hit['camera']}]: "
                  f"{top_hit['class']} (Conf: {top_hit['conf']:.2f})")
            
            # ================= æ–°å¢ï¼šå¼¹çª—æ˜¾ç¤ºä»£ç  =================
            # 1. ä»å­—å…¸ä¸­æå–å‡ºå¯¹åº”ç›¸æœºçš„åŸå›¾
            best_img = images_to_detect[top_hit['camera']].copy()
            
            # 2. æå–å‡ºä½  YOLO æ£€æµ‹å™¨è¿”å›çš„ä¸­å¿ƒç‚¹åæ ‡ cx, cy
            cx = top_hit['cx']
            cy = top_hit['cy']
            
            # 3. åœ¨ä¸­å¿ƒç‚¹ç”»ä¸€ä¸ªçº¢è‰²çš„å®å¿ƒåœ†ç‚¹ (BGR æ ¼å¼ï¼Œæ‰€ä»¥ (0, 0, 255) æ˜¯çº¢è‰²)
            cv2.circle(best_img, (cx, cy), radius=8, color=(0, 0, 255), thickness=-1)
            # å¯é€‰ï¼šå†ç”»ä¸€ä¸ªå¤§ä¸€ç‚¹çš„ç»¿è‰²ç©ºå¿ƒåœ†åœˆï¼Œåƒä¸€ä¸ªâ€œå‡†æ˜Ÿâ€
            cv2.circle(best_img, (cx, cy), radius=20, color=(0, 255, 0), thickness=2)
            
            # 4. åœ¨å‡†æ˜Ÿæ—è¾¹å†™ä¸Šç±»åˆ«å’Œç½®ä¿¡åº¦æ–‡æœ¬
            label = f"{top_hit['class']} {top_hit['conf']:.2f}"
            cv2.putText(best_img, label, (cx + 25, cy - 10), 
                        cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            
            # 5. ä½¿ç”¨ OpenCV å¼¹çª—æ˜¾ç¤ºå›¾ç‰‡
            window_name = f"Spot Detection: {top_hit['camera']}"
            cv2.imshow(window_name, best_img)
            
            print(f"ğŸ‘‰ å¼¹çª—å·²å¼€å¯ï¼Œè¯·åœ¨å›¾ç‰‡å¼¹çª— '{window_name}' ä¸ŠæŒ‰ä»»æ„é”®ç›˜æŒ‰é”®å…³é—­å¹¶ç»§ç»­ç¨‹åº...")
            cv2.waitKey(0)           # ç¨‹åºåœ¨æ­¤æš‚åœï¼Œç­‰å¾…ä½ åœ¨å¼¹çª—ä¸ŠæŒ‰ä»»æ„é”®
            cv2.destroyAllWindows()  # æŒ‰é”®åå…³é—­æ‰€æœ‰ OpenCV çª—å£
            # ======================================================
            
            return top_hit
            
        return None
    
    @SpotTracker("Scanning", exit_on_fail=False)
    def find_target(self, yolo_detector):
        print("Scanning for targets")
        #camera_sources = ["hand_color_image"]
        camera_sources = [
            'hand_color_image'
        ]
        image_requests = [build_image_request(src) for src in camera_sources]
        try:
            image_responses = self.img_client.get_image(image_requests) # type: ignore
        except Exception as e:
            print(f"Failed to acquire images: {e}")
            return None
        images_to_detect = {}
        resp_map = {} 
        for img_resp in image_responses: # type: ignore
            cam_name = img_resp.source.name # type: ignore
            resp_map[cam_name] = img_resp
            img_data = np.frombuffer(img_resp.shot.image.data, dtype=np.uint8) # type: ignore
            cv_img = cv2.imdecode(img_data, cv2.IMREAD_COLOR)
            if cv_img is not None:
                images_to_detect[cam_name] = cv_img 
        if not images_to_detect:
            print("Failed to decode any images for detection.")
            return None
            
        print("[Grasp] ğŸ§  å›¾åƒè·å–æˆåŠŸï¼Œå¼€å§‹ YOLO è¯†åˆ«...")
        detections = yolo_detector.detect_targets_in_batch(images_to_detect, conf=0.1)
        if not detections:
            print("[Grasp] âŒ æœªèƒ½åœ¨å½“å‰è§†é‡ä¸­æ‰¾åˆ°ä»»ä½•ç›®æ ‡ã€‚")
            return None
            
        top_hit = detections[0]
        cam_name = top_hit["camera"]
        cx, cy = top_hit["cx"], top_hit["cy"]
        cls_name = top_hit["class"]
        
        # âš ï¸ å…³é”®ä¿®å¤ï¼šå¿…é¡»æŠŠå½“æ—¶çš„å›¾åƒå“åº”å¯¹è±¡ä¹Ÿè¿”å›ï¼ŒæŠ“å–æ—¶éœ€è¦é‡Œé¢çš„ç›¸æœºå†…å‚å’Œåæ ‡ç³»å¿«ç…§
        target_img_resp = resp_map[cam_name]
        return target_img_resp, cam_name, cx, cy, cls_name
    
    @SpotTracker("Scanning", exit_on_fail=False)
    def find_target_2(self, yolo_detector):
        print("Scanning for targets")
        
        # 1. å®šä¹‰è§†è§‰ç›¸æœºä¸å…¶å¯¹åº”çš„â€œå¯¹é½æ·±åº¦ç›¸æœºâ€æ˜ å°„å…³ç³»
        VISUAL_TO_DEPTH_MAP = {
            'hand_color_image': 'hand_depth_in_hand_color_frame',
            'left_fisheye_image': 'left_depth_in_visual_frame',
            'right_fisheye_image': 'right_depth_in_visual_frame'
        }
        
        camera_sources = list(VISUAL_TO_DEPTH_MAP.keys())
        depth_sources = list(VISUAL_TO_DEPTH_MAP.values())
        
        # å°†è§†è§‰å›¾å’Œæ·±åº¦å›¾ä¸€å¹¶è¯·æ±‚ï¼Œä¿è¯å¿«ç…§æ—¶é—´æˆ³ä¸€è‡´
        all_sources = camera_sources + depth_sources
        image_requests = [build_image_request(src) for src in all_sources]
        
        try:
            image_responses = self.img_client.get_image(image_requests) # type: ignore
        except Exception as e:
            print(f"Failed to acquire images: {e}")
            return None
            
        images_to_detect = {}
        depth_images = {}
        resp_map = {} 
        
        # 2. åˆ†ç±»è§£æè§†è§‰å›¾åƒå’Œæ·±åº¦å›¾åƒ
        for img_resp in image_responses: # type: ignore
            cam_name = img_resp.source.name # type: ignore
            resp_map[cam_name] = img_resp
            
            # è§£ææ·±åº¦å›¾
            if cam_name in depth_sources:
                try:
                    # Spot çš„æ·±åº¦å›¾é€šå¸¸æ˜¯ 16-bit æ ¼å¼ï¼Œå•ä½æ˜¯æ¯«ç±³ (mm)
                    # å¦‚æœæ ¼å¼æ˜¯ RAWï¼Œä½¿ç”¨ numpy è§£æï¼›å¦‚æœæ˜¯å‹ç¼©æ ¼å¼ï¼ˆå¦‚PNGï¼‰ï¼Œä½¿ç”¨ OpenCV AnyDepth è§£æ
                    if img_resp.shot.image.format == img_resp.shot.image.FORMAT_RAW:
                        img_data = np.frombuffer(img_resp.shot.image.data, dtype=np.uint16)
                        cv_depth = img_data.reshape(img_resp.shot.image.rows, img_resp.shot.image.cols)
                    else:
                        img_data = np.frombuffer(img_resp.shot.image.data, dtype=np.uint8)
                        cv_depth = cv2.imdecode(img_data, cv2.IMREAD_ANYDEPTH)
                        
                    if cv_depth is not None:
                        depth_images[cam_name] = cv_depth
                except Exception as e:
                    print(f"Failed to decode depth image for {cam_name}: {e}")
                    
            # è§£æå½©è‰²/è§†è§‰å›¾
            else:
                img_data = np.frombuffer(img_resp.shot.image.data, dtype=np.uint8) # type: ignore
                cv_img = cv2.imdecode(img_data, cv2.IMREAD_COLOR)
                if cv_img is not None:
                    images_to_detect[cam_name] = cv_img 
                    
        if not images_to_detect:
            print("Failed to decode any images for detection.")
            return None
            
        print("[Grasp] ğŸ§  å›¾åƒè·å–æˆåŠŸï¼Œå¼€å§‹ YOLO è¯†åˆ«...")
        detections = yolo_detector.detect_targets_in_batch(images_to_detect, conf=0.1)
        if not detections:
            print("[Grasp] âŒ æœªèƒ½åœ¨å½“å‰è§†é‡ä¸­æ‰¾åˆ°ä»»ä½•ç›®æ ‡ã€‚")
            return None
            
        # 3. è·ç¦»æ ¡éªŒè¿‡æ»¤ (æœ€å¤§è·ç¦» 4 ç±³)
        MAX_DISTANCE_MM = 4000 
        valid_detections = []
        
        for hit in detections:
            cam_name = hit["camera"]
            cx, cy = int(hit["cx"]), int(hit["cy"])
            depth_cam_name = VISUAL_TO_DEPTH_MAP.get(cam_name)
            
            if depth_cam_name and depth_cam_name in depth_images:
                depth_img = depth_images[depth_cam_name]
                
                # ç¡®ä¿æå–åæ ‡æ²¡æœ‰è¶Šç•Œ
                if 0 <= cy < depth_img.shape[0] and 0 <= cx < depth_img.shape[1]:
                    distance_mm = depth_img[cy, cx]
                    
                    # è·ç¦»è¿‡æ»¤ï¼š>0 æ’é™¤ä¼ æ„Ÿå™¨ç›²åŒºå¤±æ•ˆé»‘æ´ï¼Œ<= 4000 ç¡®ä¿åœ¨4ç±³èŒƒå›´å†…
                    if 0 < distance_mm <= MAX_DISTANCE_MM:
                        hit["distance_mm"] = distance_mm # è®°å½•è·ç¦»å¤‡ç”¨
                        valid_detections.append(hit)
                        print(f"âœ”ï¸ ç›®æ ‡æœ‰æ•ˆ: {hit['class']} åœ¨ {distance_mm/1000.0:.2f}ç±³å¤„.")
                    else:
                        print(f"âŒ ç›®æ ‡è¿‡æ»¤: {hit['class']} åœ¨ {distance_mm/1000.0:.2f}ç±³å¤„ (è¶…å‡º4ç±³èŒƒå›´æˆ–æ— æ•ˆ).")
                else:
                    print(f"âš ï¸ è¶Šç•Œ: ({cx}, {cy}) ä¸åœ¨æ·±åº¦å›¾èŒƒå›´å†….")
            else:
                # å®¹é”™å¤„ç†ï¼šå¦‚æœæ²¡æœ‰è·å–åˆ°æ·±åº¦å›¾ï¼Œé»˜è®¤å…ˆä¿ç•™è¯¥ç›®æ ‡ï¼ˆè§†ä½ å®é™…å®‰å…¨éœ€æ±‚ä¹Ÿå¯ç›´æ¥ä¸¢å¼ƒï¼‰
                print(f"âš ï¸ ç¼ºå°‘å¯¹åº”çš„æ·±åº¦æ•°æ®ï¼Œä¿å®ˆä¿ç•™ {hit['class']} ç›®æ ‡.")
                valid_detections.append(hit)

        if not valid_detections:
            print("[Grasp] âŒ è§†é‡å†…å‘ç°äº†ç›®æ ‡ï¼Œä½†å‡åœ¨4ç±³ä»¥å¤–æˆ–ä¸å¯è¾¾èŒƒå›´ï¼Œä¸¢å¼ƒã€‚")
            return None
            
        # è¿™é‡Œé»˜è®¤å–äº†æœ‰æ•ˆç›®æ ‡ä¸­çš„ç¬¬ä¸€ä¸ªï¼Œä½ ä¹Ÿå¯ä»¥æ”¹ä¸ºæ ¹æ® distance_mm æ’åºå–æœ€è¿‘çš„
        # top_hit = sorted(valid_detections, key=lambda x: x.get("distance_mm", float('inf')))[0]
        top_hit = valid_detections[0]
        
        cam_name = top_hit["camera"]
        cx, cy = top_hit["cx"], top_hit["cy"]
        cls_name = top_hit["class"]
        
        # âš ï¸ å…³é”®ä¿®å¤ï¼šè¿”å›å½“æ—¶çš„å›¾åƒå“åº”å¯¹è±¡ï¼ŒæŠ“å–æ—¶éœ€è¦é‡Œé¢çš„ç›¸æœºå†…å‚å’Œåæ ‡ç³»å¿«ç…§
        target_img_resp = resp_map[cam_name]
        return target_img_resp, cam_name, cx, cy, cls_name
    

    @SpotTracker("Grasping", exit_on_fail=False)
    def grasp_object(self, target_img_resp, cam_name, cx, cy, cls_name, timeout_sec=30.0):
        """
        æ‰§è¡ŒæŠ“å–åŠ¨ä½œï¼ŒåŒ…å«çŠ¶æ€ç›‘æ§ã€é˜²å‘†éªŒè¯å’Œè¶…æ—¶æ¢å¤ã€‚
        """
        print(f"Grasping object {cls_name} at ({cx}, {cy}) in camera {cam_name}")
        
        from bosdyn.client.frame_helpers import VISION_FRAME_NAME, GRAV_ALIGNED_BODY_FRAME_NAME, math_helpers
        from bosdyn.client.robot_command import RobotCommandBuilder

        pick_vec = geometry_pb2.Vec2(x=cx, y=cy) # type: ignore
        grasp = manipulation_api_pb2.PickObjectInImage( # type: ignore
            pixel_xy=pick_vec, 
            transforms_snapshot_for_camera=target_img_resp.shot.transforms_snapshot, 
            frame_name_image_sensor=target_img_resp.shot.frame_name_image_sensor, 
            camera_model=target_img_resp.source.pinhole 
        )
        
        grasp.grasp_params.grasp_params_frame_name = VISION_FRAME_NAME
        
        #constraint_top_down = grasp.grasp_params.allowable_orientation.add()
        #constraint_top_down.vector_alignment_with_tolerance.axis_on_gripper_ewrt_gripper.CopyFrom(geometry_pb2.Vec3(x=1, y=0, z=0)) # type: ignore
        #constraint_top_down.vector_alignment_with_tolerance.axis_to_align_with_ewrt_frame.CopyFrom(geometry_pb2.Vec3(x=0, y=0, z=-1)) # type: ignore
        # å®¹å·®æ”¾å®½åˆ° 0.25 (çº¦ 15åº¦)ï¼Œç»™æœºæ¢°è‡‚ç•™å‡ºè¶³å¤Ÿçš„è¿åŠ¨ç©ºé—´
        #constraint_top_down.vector_alignment_with_tolerance.threshold_radians = 0.78 
        # =================================================================

        manip_req = manipulation_api_pb2.ManipulationApiRequest(pick_object_in_image=grasp) # type: ignore
        
        try:
            print("Sending grasp command to robot...")
            cmd_response = self.manip_client.manipulation_api_command(manipulation_api_request=manip_req) # type: ignore
            cmd_id = cmd_response.manipulation_cmd_id
            print(f"Task sent, ID: {cmd_id}")
            
            start_time = time.time()
            last_state_name = "" 
            
            while True:
                if time.time() - start_time > timeout_sec:
                    print(f"âŒ æŠ“å–è¶…æ—¶ ({timeout_sec}s)ï¼Œæ”¾å¼ƒå°è¯•ã€‚")
                    self._recover_arm_safely()
                    return False
                    
                feedback_req = manipulation_api_pb2.ManipulationApiFeedbackRequest(manipulation_cmd_id=cmd_id) # type: ignore
                response = self.manip_client.manipulation_api_feedback_command(manipulation_api_feedback_request=feedback_req) # type: ignore
                state_name = manipulation_api_pb2.ManipulationFeedbackState.Name(response.current_state) # type: ignore
                
                if state_name != last_state_name:
                    print(f"ğŸ”„ æœºå™¨äººå½“å‰åŠ¨ä½œ: {state_name}")
                    last_state_name = state_name
                
                # âš ï¸ ä¿®å¤å¡æ­»é—®é¢˜ï¼šåŒæ—¶ç›‘å¬ SUCCEEDED å’Œ DONE ä¸¤ä¸ªçŠ¶æ€
                if response.current_state in [manipulation_api_pb2.MANIP_STATE_GRASP_SUCCEEDED, manipulation_api_pb2.MANIP_STATE_DONE]: # type: ignore
                    print("âœ… æ”¶åˆ°æŠ“å–å®Œæˆä¿¡å·ï¼Œæ­£åœ¨ç‰©ç†éªŒè¯æ˜¯å¦æŠ“ç©º...")
                    time.sleep(0.5)  
                    
                    robot_state = self.state_client.get_robot_state()
                    gripper_open_pct = robot_state.manipulator_state.gripper_open_percentage
                    print(f"ğŸ” æŠ“æ‰‹å½“å‰å¼ å¼€æ¯”ä¾‹: {gripper_open_pct:.2f}%")
                    
                    if gripper_open_pct < 3.0: 
                        print("âŒ è­¦å‘Šï¼šæŠ“æ‰‹å®Œå…¨é—­åˆï¼Œè¯´æ˜æŠ“ç©ºäº†ï¼")
                        self._recover_arm_safely()
                        return False
                        
                    print("âœ… ç‰©ç†éªŒè¯é€šè¿‡ï¼Œç¡®å®æŠ“åˆ°äº†ç‰©å“ï¼")
                    
                    try:
                        # ğŸŒŸ æ–°å¢ï¼šè®©æœºå™¨ç‹—æ¢å¤é»˜è®¤ç«™ç«‹é«˜åº¦
                        print("ğŸ• æ­£åœ¨æ¢å¤æ ‡å‡†ç«™ç«‹å§¿æ€...")
                        stand_cmd = RobotCommandBuilder.synchro_stand_command()
                        # å‘é€ç«™ç«‹æŒ‡ä»¤ï¼ˆå‡è®¾ä½ çš„ cmd_client å·²ç»åˆå§‹åŒ–ï¼‰
                        self.cmd_client.robot_command(stand_cmd)
                        time.sleep(0.2) # ç»™å®ƒä¸€ç‚¹æ—¶é—´ç«™èµ·æ¥
                        
                        print("ğŸ”„ æ­£åœ¨å°†ç‰©ä½“ä¸¾é«˜åˆ°ç»å¯¹ä½ç½®...")
                        abs_x, abs_y, abs_z = 0.75, 0.0, 0.35
                        q = math_helpers.Quat.from_pitch(15.0 * math.pi / 180.0)
                        
                        lift_cmd = RobotCommandBuilder.arm_pose_command(
                            abs_x, abs_y, abs_z, q.w, q.x, q.y, q.z,
                            GRAV_ALIGNED_BODY_FRAME_NAME, 2.5 
                        )
                        self.cmd_client.robot_command(lift_cmd)
                        time.sleep(0.2) 
                        
                        carry_cmd = RobotCommandBuilder.arm_carry_command()
                        self.cmd_client.robot_command(carry_cmd) # type: ignore
                        print("âœ… å·²åˆ‡æ¢è‡³ Carry æ¨¡å¼ã€‚")
                        
                    except Exception as e:
                        print(f"âŒ ä¸¾é«˜/ç«™ç«‹åŠ¨ä½œå¤±è´¥: {e}")
                    return True
                    
                elif response.current_state == manipulation_api_pb2.MANIP_STATE_GRASP_FAILED or 'FAILED' in state_name or 'NO_SOLUTION' in state_name: # type: ignore
                    print(f"âŒ æŠ“å–å¤±è´¥/æ— è¿åŠ¨è§£: {state_name}")
                    self._recover_arm_safely()
                    return False 
                time.sleep(0.5) 
        except Exception as e:
            print(f"âŒ Error during grasp operation: {e}")
            import traceback
            traceback.print_exc()
            self._recover_arm_safely()
            return False
    
    def _recover_arm_safely(self):
        """æŠ“å–å¤±è´¥ã€æŠ“ç©ºæˆ–è¶…æ—¶æ—¶çš„å®‰å…¨å›é€€é€»è¾‘"""
        try:
            self.cmd_client.robot_command(RobotCommandBuilder.claw_gripper_open_command())
            time.sleep(0.5)
            self.cmd_client.robot_command(RobotCommandBuilder.arm_stow_command())
            print("ğŸ”„ å·²å¼ å¼€æŠ“æ‰‹å¹¶æ”¶å›æœºæ¢°è‡‚ã€‚")
        except Exception as e:
            print(f"âš ï¸ æœºæ¢°è‡‚æ”¶å›æŒ‡ä»¤å‘é€å¤±è´¥: {e}")

    # endregion

    # region Public APIs: Navigation Logic

    @SpotTracker("Navigation initialisation", exit_on_fail=False)
    def initialize_graphnav_to_fiducial(self, fiducial_id: Optional[int] = None):
        print("Determine initial position for GraphNav localization...")
        try:
            initial_guess = nav_pb2.Localization()
            if fiducial_id is not None:

                self.graph_nav_client.set_localization( # type: ignore
                    initial_guess_localization=initial_guess,  
                    fiducial_init=graph_nav_pb2.SetLocalizationRequest.FIDUCIAL_INIT_SPECIFIC, # type: ignore
                    use_fiducial_id=fiducial_id
                )
            else:
                self.graph_nav_client.set_localization( # type: ignore
                    initial_guess_localization=initial_guess, 
                    fiducial_init=graph_nav_pb2.SetLocalizationRequest.FIDUCIAL_INIT_NEAREST # type: ignore
                )
            state = self.graph_nav_client.get_localization_state() # type: ignore
            if not state.localization.waypoint_id: # type: ignore
                print("No QR code detected for localisation! Please make sure Spot can see the fiducials, and try again.")
                return False
            print(f"Localisation success: Spot is near {state.localization.waypoint_id[:6]}") # type: ignore
            return True
        except Exception as e:
            print(f"Error during localisation: {e}")
            return False
        
    @SpotTracker("Navigate to waypoint", exit_on_fail=False)
    def navigate_to_waypoint(self, destination_wp_id: str, timeout_sec: float = 60.0):
        print(f"Navigate to: {destination_wp_id[:6]}...")
        try:
            nav_cmd_id = self.graph_nav_client.navigate_to( # type: ignore
                destination_waypoint_id=destination_wp_id,
                cmd_duration=timeout_sec
            )
            start_time = time.time()
            while True:
                current_time = time.time()
                if current_time - start_time > timeout_sec:
                    print(f"Navigation timeout ({timeout_sec}s), abandoning attempt.")
                    return False
                feedback = self.graph_nav_client.navigation_feedback(nav_cmd_id) # type: ignore
                status = feedback.status # type: ignore
                if status == graph_nav_pb2.NavigationFeedbackResponse.STATUS_REACHED_GOAL: # type: ignore
                    print("Reached destination! Navigation successful.")
                    return True
                elif status == graph_nav_pb2.NavigationFeedbackResponse.STATUS_LOST: # type: ignore
                    print("Spot has lost localization. Attempting to re-localise...")
                    return False
                elif status == graph_nav_pb2.NavigationFeedbackResponse.STATUS_STUCK: # type: ignore
                    print("Spot is stuck and cannot reach the destination. Please check for obstacles or narrow passages, and try again.")
                time.sleep(0.5)
        except Exception as e:
            print(f"Error: {e}")
            return False
        
    @SpotTracker("Loading graph", exit_on_fail=False)
    def get_current_graph(self):
        print("Reading graph from robot memory...")
        try:
            graph = self.graph_nav_client.download_graph() # type: ignore
            
            if not graph.waypoints: # type: ignore
                print("No waypoints found in the graph! Please make sure the robot has a valid map and try again.")
                return None
            print(f"Graph found. Current graph including {len(graph.waypoints)} warypoints, {len(graph.edges)} edgesã€‚") # type: ignore
            return graph
        except Exception as e:
            print(f"Error reading graph: {e}")
            return None
    
    def get_waypoint_id_by_name(self, graph, target_name: str) -> str:
        available_names = []
        for wp in graph.waypoints:
            wp_name = wp.annotations.name
            available_names.append(wp_name)
            if wp_name.lower() == target_name.lower():
                print(f"Found target '{target_name}'. Accquired ID:  {wp.id[:6]}...")
                return wp.id
        print(f"Can not find waypoint named '{target_name}'!")
        print(f"Available waypoints: {', '.join(available_names)}")
        return None # type: ignore
    
    @SpotTracker("Uploading graph and snapshots", exit_on_fail=False)
    def upload_graph_and_snapshots(self, save_dir: str): 
        print(f"Upload '{save_dir}' to spot")
        self.graph_nav_client.clear_graph() # type: ignore
        graph_path = os.path.join(save_dir, "graph")
        if not os.path.exists(graph_path):
            print(f"[GraphNav] âŒ æ‰¾ä¸åˆ°åœ°å›¾æ–‡ä»¶: {graph_path}")
            return None
        with open(graph_path, "rb") as f:
            graph = map_pb2.Graph()
            graph.ParseFromString(f.read()) # type: ignore
        print("Uploading graph structure...")
        self.graph_nav_client.upload_graph(graph=graph, generate_new_anchoring=True) # type: ignore
        print("Uploading waypoint snapshots...")
        for wp in graph.waypoints: # type: ignore
            if wp.snapshot_id:
                wp_path = os.path.join(save_dir, f"wp_{wp.snapshot_id}")
                if os.path.exists(wp_path):
                    with open(wp_path, "rb") as f:
                        snap = map_pb2.WaypointSnapshot()
                        snap.ParseFromString(f.read())  # type: ignore
                        for img in snap.images:   # type: ignore
                            img.shot.image.data = b"" 
                        self.graph_nav_client.upload_waypoint_snapshot(snap) # type: ignore
                else:
                    print(f" Missing waypoint snapshot file: {wp_path}")
        print("Uploading edge snapshots...")
        for edge in graph.edges: # type: ignore
            if edge.snapshot_id:
                edge_path = os.path.join(save_dir, f"edge_{edge.snapshot_id}")
                if os.path.exists(edge_path):
                    with open(edge_path, "rb") as f:
                        snap = map_pb2.EdgeSnapshot()
                        snap.ParseFromString(f.read()) # type: ignore
                        self.graph_nav_client.upload_edge_snapshot(snap) # type: ignore
                else:
                    print(f" Missing edge snapshot file: {edge_path}")
        print("Graph upload complete.")
        return graph
