# ===== =================== =====
# ===== RMIT Spot control class =====
# ===== =================== =====
import time
import math
import cv2
import threading
from typing import Optional
import numpy as np
# ===== For web ui =====
from flask import Flask, Response, render_template_string
# ===== BostonDynamic APIs =====
import bosdyn.client
from bosdyn.api import image_pb2
from bosdyn.client.image import build_image_request, ImageClient
from bosdyn.client.lease import LeaseClient, LeaseKeepAlive
from bosdyn.client.robot_command import RobotCommandClient, RobotCommandBuilder, blocking_stand, block_until_arm_arrives
from bosdyn.client.robot_state import RobotStateClient
from bosdyn.client.robot_command import RobotCommandBuilder
from bosdyn.client.frame_helpers import (
    GRAV_ALIGNED_BODY_FRAME_NAME,
    HAND_FRAME_NAME,
    ODOM_FRAME_NAME,     
    VISION_FRAME_NAME,
    BODY_FRAME_NAME,   
    get_a_tform_b,
    math_helpers
)
from bosdyn.client.math_helpers import SE3Pose, Quat
from bosdyn.client.manipulation_api_client import ManipulationApiClient
from bosdyn.api import geometry_pb2, manipulation_api_pb2

class SpotAgent:

    # region  Private APIs: Initialisation

    def __init__(
        self,
        hostname: str,
        username: str,
        password: str,
        *,
        client_name: str = "SpotAgent",
        keep_alive_period_sec: float = 2.0,
        force_lease: bool = True,
    ):
        self.hostname = hostname
        self.client_name = client_name
        self.keep_alive_period_sec = keep_alive_period_sec
        self.sdk: Optional[bosdyn.client.Sdk] = None
        self.robot: Optional[bosdyn.client.Robot] = None
        self.lease_client: Optional[LeaseClient] = None
        self.cmd_client: Optional[RobotCommandClient] = None
        self.img_client: Optional[ImageClient] = None
        self.state_client: Optional[RobotStateClient] = None
        self._lease_keepalive: Optional[LeaseKeepAlive] = None
        self.default_hold = 0.9 
        self._auto_login(username, password)
        self._get_lease(force=force_lease)
        self.origin_x = 0.0
        self.origin_y = 0.0
        self.origin_yaw = 0.0
        self.home_x = 0.0
        self.home_y = 0.0
        self.home_yaw = 0.0
        self.guard_x = 0.0
        self.guard_y = 0.0
        self.guard_yaw = 0.0
        self._latest_grid = None
        self._streaming = True
        
    def __enter__(self):
        threading.Thread(target=self._stream_loop, daemon=True).start()
        self._start_web_server(host="0.0.0.0", port=5555)
        time.sleep(1)
        self._power_on_and_stand()
        self._arm_out()
        return self

    def __exit__(self, *args):
        self._shutdown()

    # endregion

    # region  Private APIs: Spot admin

    def _auto_login(
            self, 
            username: str, 
            password: str
        ):
        self.sdk = bosdyn.client.create_standard_sdk(self.client_name)
        self.robot = self.sdk.create_robot(self.hostname)
        self.robot.authenticate(username, password)
        try:
            self.robot.time_sync.wait_for_sync()
        except Exception:
            self.robot.time_sync.start()
            self.robot.time_sync.wait_for_sync()
        self.lease_client = self.robot.ensure_client(LeaseClient.default_service_name)
        self.cmd_client = self.robot.ensure_client(RobotCommandClient.default_service_name)
        self.img_client = self.robot.ensure_client(ImageClient.default_service_name)
        self.state_client = self.robot.ensure_client(RobotStateClient.default_service_name)

    def _make_keepalive(
            self, 
            *, 
            must_acquire: bool, 
            return_at_exit: bool
        ) -> LeaseKeepAlive:
        try:
            return LeaseKeepAlive(
                self.lease_client,
                must_acquire=must_acquire,
                return_at_exit=return_at_exit,
                period_sec=self.keep_alive_period_sec,
            )
        except TypeError:
            return LeaseKeepAlive(
                self.lease_client,
                must_acquire=must_acquire,
                return_at_exit=return_at_exit,
            )

    def _get_lease(
            self, 
            force: bool = False
        ) -> LeaseKeepAlive:
        if self.lease_client is None:
            raise RuntimeError("lease_client not yet initialised.")
        if self._lease_keepalive is not None:
            try:
                self._lease_keepalive.shutdown()
            except Exception:
                pass
            self._lease_keepalive = None
        if force:
            try:
                self.lease_client.take()
            except Exception:
                self.lease_client.acquire()
            self._lease_keepalive = self._make_keepalive(must_acquire=False, return_at_exit=True)
        else:
            self._lease_keepalive = self._make_keepalive(must_acquire=True, return_at_exit=True)
        return self._lease_keepalive
    
    def _power_on_and_stand(
            self, 
            timeout_sec: float = 20.0, 
            stand_timeout_sec: float = 10.0
        ):
        if self.robot is None or self.cmd_client is None:
            raise RuntimeError("Require login")
        if not self.robot.is_powered_on():
            print("[robot] Power up...")
            self.robot.power_on(timeout_sec=timeout_sec)
        print("[robot] Standing up...")
        blocking_stand(self.cmd_client, timeout_sec=stand_timeout_sec)
    
    def _shutdown(
            self, 
            power_off: bool = False
            ):
        if self._lease_keepalive is not None:
            try:
                self._lease_keepalive.shutdown()
            except Exception:
                pass
            self._lease_keepalive = None
        if power_off and self.robot is not None:
            try:
                self.robot.power_off(cut_immediately=False)
            except Exception:
                pass
    
    
    # endregion

    # region  Private APIs: Tools

    @staticmethod
    def _yaw_from_quat(q) -> float:
        return math.atan2(2.0 * (q.w * q.z + q.x * q.y),
                          1.0 - 2.0 * (q.y * q.y + q.z * q.z))
    
    # endregion
    
    # region  Private APIs: Web streaming

    def _start_web_server(self, host="0.0.0.0", port=5555):
        app = Flask(__name__)
        @app.route('/')
        def index():
            # æç®€çš„ HTML é¡µé¢ï¼Œæ˜¾ç¤ºæµç”»é¢
            return render_template_string("""
                <html>
                <head><title>Spot 360 View</title></head>
                <body style="background: #111; display: flex; justify-content: center; align-items: center; height: 100vh; margin: 0;">
                    <img src="/video_feed" style="width: 80%; border: 2px solid #555;">
                </body>
                </html>
            """)
        def gen_frames():
            while True:
                if self._latest_grid is not None:
                    # å°† OpenCV å›¾åƒè½¬ä¸º JPG æ ¼å¼
                    ret, buffer = cv2.imencode('.jpg', self._latest_grid)
                    frame = buffer.tobytes()
                    # ä½¿ç”¨ MJPEG æ ¼å¼æ‹¼æ¥
                    yield (b'--frame\r\n'
                           b'Content-Type: image/jpeg\r\n\r\n' + frame + b'\r\n')
                time.sleep(0.05) # é™åˆ¶ 20fps å·¦å³ï¼ŒèŠ‚çœ CPU
        @app.route('/video_feed')
        def video_feed():
            return Response(gen_frames(), mimetype='multipart/x-mixed-replace; boundary=frame')
        threading.Thread(target=lambda: app.run(host=host, port=port, debug=False, use_reloader=False), daemon=True).start()
        print(f"[WebUI] Server started at http://{host}:{port}")

    def _stream_loop(self):
        image_client = self.robot.ensure_client("image")
        source_names = [
            'hand_color_image',       
            'left_fisheye_image',     
            'right_fisheye_image',    
            'back_fisheye_image'      
        ]
        display_names = {
            'hand_color_image': 'Front (Hand)',
            'left_fisheye_image': 'Left',
            'right_fisheye_image': 'Right',
            'back_fisheye_image': 'Back'
        }
        camera_rotations = {
            'hand_color_image': 0,       
            'left_fisheye_image': 0,
            'right_fisheye_image': 180,  
            'back_fisheye_image': 0
        }
        W_STD, H_STD = 320, 240
        W_WIDE, H_WIDE = 640, 480
        reqs = [
            build_image_request(src, pixel_format=image_pb2.Image.PIXEL_FORMAT_RGB_U8, quality_percent=70) 
            for src in source_names
        ]
        while self._streaming:
            try:
                responses = image_client.get_image(reqs)
                img_map = {}
                empty_std = np.zeros((H_STD, W_STD, 3), dtype=np.uint8)
                empty_wide = np.zeros((H_WIDE, W_WIDE, 3), dtype=np.uint8)
                for res in responses:
                    source_name = res.source.name
                    if res.status == image_pb2.ImageResponse.STATUS_OK:
                        arr = np.frombuffer(res.shot.image.data, dtype=np.uint8)
                        decoded = cv2.imdecode(arr, cv2.IMREAD_COLOR)
                        if decoded is not None:
                            angle = camera_rotations.get(source_name, 0) % 360
                            rotated = decoded
                            if angle == 90: rotated = cv2.rotate(decoded, cv2.ROTATE_90_COUNTERCLOCKWISE)
                            elif angle == 180: rotated = cv2.rotate(decoded, cv2.ROTATE_180)
                            elif angle == 270: rotated = cv2.rotate(decoded, cv2.ROTATE_90_CLOCKWISE)
                            elif angle != 0:
                                h_o, w_o = decoded.shape[:2]
                                M = cv2.getRotationMatrix2D((w_o//2, h_o//2), angle, 1.0)
                                rotated = cv2.warpAffine(decoded, M, (w_o, h_o))
                            if source_name in ['hand_color_image', 'back_fisheye_image']:
                                target_w, target_h = W_WIDE, H_WIDE
                                font_scale = 1.0
                            else:
                                target_w, target_h = W_STD, H_STD
                                font_scale = 0.7
                            final_img = cv2.resize(rotated, (target_w, target_h))
                            label = display_names.get(source_name, source_name)
                            cv2.putText(final_img, label, (10, 40), 
                                        cv2.FONT_HERSHEY_SIMPLEX, font_scale, (0, 255, 0), 2)
                            img_map[source_name] = final_img
                # ==========================================
                # 1. ç¬¬ä¸€è¡Œå’Œç¬¬äºŒè¡Œ (åŸç›¸æœºç”»é¢)
                # ==========================================
                row1_front = img_map.get('hand_color_image', empty_wide)
                row2_side = np.hstack([
                    img_map.get('left_fisheye_image', empty_std),
                    img_map.get('right_fisheye_image', empty_std)
                ])
                
                # ==========================================
                # 2. ç¬¬ä¸‰è¡Œï¼šç”Ÿæˆ 2D ä¿¯è§†å¹³é¢å›¾ (å®½640 é«˜480)
                # ==========================================
                map_img = np.zeros((H_WIDE, W_WIDE, 3), dtype=np.uint8)
                
                # ç”»èƒŒæ™¯ç½‘æ ¼ (å¢å¼ºè§†è§‰æ•ˆæœ)
                grid_size = 40
                for i in range(0, W_WIDE, grid_size):
                    cv2.line(map_img, (i, 0), (i, H_WIDE), (30, 30, 30), 1)
                for i in range(0, H_WIDE, grid_size):
                    cv2.line(map_img, (0, i), (W_WIDE, i), (30, 30, 30), 1)
                    
                # å®šä¹‰åœ°å›¾ä¸­å¿ƒ(å³åŸç‚¹)
                cx, cy = W_WIDE // 2, H_WIDE // 2
                cv2.drawMarker(map_img, (cx, cy), (255, 255, 255), cv2.MARKER_CROSS, 20, 2)
                cv2.putText(map_img, "Origin", (cx + 10, cy - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 1)
                
                # æ¯”ä¾‹å°º: 1ç±³ = 100ä¸ªåƒç´ 
                scale = 100 
                
                # æ¸²æŸ“æ‰«æåˆ°çš„ Bottle / Can åæ ‡
                if hasattr(self, '_latest_objects') and self._latest_objects:
                    for obj in self._latest_objects:
                        obj_x = obj['x']
                        obj_y = obj['y']
                        cam = obj['camera_name'].split('_')[0] # å–å‡º hand/left ç­‰å‰ç¼€
                        
                        # ç‰©ç†åæ ‡ç³»æ˜ å°„è‡³åƒç´ ç³» (Spot vision åæ ‡ä¸­ï¼ŒXå‰ï¼ŒYå·¦)
                        # OpenCVå›¾åƒä¸­ï¼ŒXå‘å³ï¼ŒYå‘ä¸‹
                        # æ‰€ä»¥æˆ‘ä»¬è®©åœ°å›¾çš„ Yè½´(å‚ç›´)å¯¹åº”ç‰©ç† Xè½´ï¼Œåœ°å›¾çš„ Xè½´(æ°´å¹³)å¯¹åº”ç‰©ç† Yè½´çš„è´Ÿæ–¹å‘
                        px = int(cx - obj_y * scale)
                        py = int(cy - obj_x * scale)
                        
                        # è‹¥ç‚¹åœ¨ç”»å¸ƒå†…ï¼Œåˆ™ç”»å‡ºçº¢ç‚¹ä¸å¤–åœˆ
                        if 0 <= px < W_WIDE and 0 <= py < H_WIDE:
                            cv2.circle(map_img, (px, py), 8, (0, 0, 255), -1)    # å†…éƒ¨çº¢è‰²å®ä½“
                            cv2.circle(map_img, (px, py), 12, (0, 255, 255), 2)  # å¤–å›´é»„è‰²è­¦å‘Šåœˆ
                            cv2.putText(map_img, f"Target({cam})", (px + 15, py + 5), 
                                        cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 1)

                cv2.putText(map_img, "2D Target Plan (1m=100px)", (15, 30), 
                            cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)

                # å‚ç›´å †å ä¸‰è¡Œï¼Œæœ€ç»ˆç”»é¢å°†å˜æˆ 640x1200
                self._latest_grid = np.vstack([row1_front, row2_side, map_img])
                
            except Exception as e:
                print(f"[Stream Err] {e}")
                time.sleep(0.5)
    # endregion

    # region  Private APIs: Basic actions
    
    def _arm_out(self):
        if self.cmd_client is None or self.img_client is None:
            raise RuntimeError("cmd_client/img_client æœªåˆå§‹åŒ–ã€‚")
        try:
            snapshot = self.state_client.get_robot_state().kinematic_state.transforms_snapshot
            root_frame = GRAV_ALIGNED_BODY_FRAME_NAME
            root_T_hand = get_a_tform_b(snapshot, root_frame, HAND_FRAME_NAME)
            delta_hand = math_helpers.SE3Pose(
                x = 0.30,   # åœ¨ X è½´æ–¹å‘ï¼ˆå‰æ–¹ï¼‰ç§»åŠ¨ 0.3 ç±³
                y = 0.0,    # å·¦å³ä¸åç§»
                z = -0.25,  # åœ¨ Z è½´æ–¹å‘å‘ä¸‹ç§»åŠ¨ 0.25 ç±³
                rot = math_helpers.Quat.from_pitch(15.0 * math.pi / 180.0) # å‘ä¸‹ä½å¤´ 30 åº¦
            )
            root_T_target = root_T_hand * delta_hand
            q = root_T_target.rot
            arm_cmd = RobotCommandBuilder.arm_pose_command(
                root_T_target.x, root_T_target.y, root_T_target.z,
                q.w, q.x, q.y, q.z, root_frame, 1.2 # 1.2 ç§’å†…å®ŒæˆåŠ¨ä½œ
            )
            self.cmd_client.robot_command(arm_cmd)
            self.cmd_client.robot_command(RobotCommandBuilder.claw_gripper_open_command())
            time.sleep(0.4)
            print("[Arm] Arm ready.")
        except Exception as e:
            print(f"[Arm] Arm failed:{e}")
    
    def _arm_in(self):
        if self.cmd_client is None:
            raise RuntimeError("cmd_client æœªåˆå§‹åŒ–ã€‚")
        try:
            self.cmd_client.robot_command(RobotCommandBuilder.claw_gripper_close_command())
            stow_cmd = RobotCommandBuilder.arm_stow_command()
            self.cmd_client.robot_command(stow_cmd)
            print("[Arm] Arm stowing...")
        except Exception as e:
            print(f"[Arm] Stow failed: {e}")    

    # endregion

    # region  Public APIs: Basic actions
    
    def move_to_goal(
            self, 
            x, 
            y, 
            angle_deg, 
            frame="vision", 
            use_local_origin=True
        ):
        goal_yaw = math.radians(angle_deg)
        target_frame = VISION_FRAME_NAME if frame == "vision" else ODOM_FRAME_NAME
        if use_local_origin:
            final_x = self.origin_x + (x * math.cos(self.origin_yaw) - y * math.sin(self.origin_yaw))
            final_y = self.origin_y + (x * math.sin(self.origin_yaw) + y * math.cos(self.origin_yaw))
            final_yaw = self.origin_yaw + goal_yaw
        else:
            final_x, final_y, final_yaw = x, y, goal_yaw
        now = self.robot.time_sync.robot_timestamp_from_local_secs(time.time())
        end_time_sec = now.seconds + (now.nanos / 1e9) + 10.0
        cmd = RobotCommandBuilder.synchro_se2_trajectory_point_command(
            goal_x=final_x, goal_y=final_y, goal_heading=final_yaw, frame_name=target_frame
        )
        self.cmd_client.robot_command(cmd, end_time_secs=end_time_sec)
        print(f"[GoTo] Logic Target: ({x}, {y}, {angle_deg}Â°) -> SDK Target: ({final_x:.2f}, {final_y:.2f})")
 
    def scan(self, detector) -> list:
        print("\n[Guard] æ­£åœ¨æ‰«æå…¨å‘ç¯å¢ƒå¯»æ‰¾æ‰€æœ‰ç›®æ ‡...")
        sources = [
            'hand_color_image', 
            'left_fisheye_image', 
            'right_fisheye_image', 
            'back_fisheye_image'
        ]
        camera_rotations = {
            'left_fisheye_image': 0,
            'right_fisheye_image': 180,  
            'hand_color_image': 0,       
            'back_fisheye_image': 0
        }
        image_client = self.robot.ensure_client('image')
        reqs = [build_image_request(src, quality_percent=70) for src in sources]
        try:
            responses = image_client.get_image(reqs)
        except Exception as e:
            print(f"[Guard] è·å–å›¾åƒå¤±è´¥: {e}")
            return []
        raw_responses = {}
        images_dict = {}
        cam_meta = {} 
        for res in responses:
            if res.status == image_pb2.ImageResponse.STATUS_OK:
                cam_name = res.source.name
                raw_responses[cam_name] = res
                img_np = np.frombuffer(res.shot.image.data, dtype=np.uint8)
                img = cv2.imdecode(img_np, cv2.IMREAD_COLOR)
                if img is not None:
                    orig_h, orig_w = img.shape[:2]
                    angle = camera_rotations.get(cam_name, 0) % 360
                    rotated_img = img
                    if angle == 180:
                        rotated_img = cv2.rotate(img, cv2.ROTATE_180)
                    images_dict[cam_name] = rotated_img
                    cam_meta[cam_name] = {"orig_w": orig_w, "orig_h": orig_h, "angle": angle}
        if not images_dict:
            return []
        results = detector.detect_targets_in_batch(images_dict, conf=0.05)
        detection_list = []
        if results:
            print(f"[Guard] å‘ç° {len(results)} ä¸ªæ½œåœ¨ç›®æ ‡ï¼Œæ­£åœ¨åæ¨åŸå§‹åæ ‡...")
            for best in results:
                cam_name = best['camera']
                cx, cy = best.get('cx', 0), best.get('cy', 0)
                meta = cam_meta[cam_name]
                orig_w, orig_h, angle = meta['orig_w'], meta['orig_h'], meta['angle']
                raw_pixel_x, raw_pixel_y = cx, cy
                if angle == 180:
                    raw_pixel_x = orig_w - cx - 1
                    raw_pixel_y = orig_h - cy - 1
                print(f"        -> [{cam_name}] åŸå§‹åƒç´ åæ ‡: ({raw_pixel_x:.1f}, {raw_pixel_y:.1f})")
                detection_list.append((raw_responses[cam_name], raw_pixel_x, raw_pixel_y))
        else:
            print("[Guard] æœªå‘ç°ç›®æ ‡ã€‚")
        return detection_list

    def point_arm_to_pixel(self, detection_result: tuple, assumed_dist: float = 1.0) -> bool:
        """
        æ¥æ”¶è§†è§‰è¿”å›å€¼ï¼Œè®¡ç®— 3D åæ ‡ï¼š
        1. æ§åˆ¶æœºå™¨ç‹—åº•ç›˜åŸåœ°æ—‹è½¬ï¼Œé¢æœç›®æ ‡ã€‚
        2. å°†æ‰‹è‡‚å‘å‰ä¼¸å‡ºï¼Œå¹¶è°ƒæ•´æ‰‹çˆªå§¿æ€æŒ‡å‘ç›®æ ‡ã€‚
        """
        import math
        import time
        from bosdyn.client.frame_helpers import (
            VISION_FRAME_NAME, HAND_FRAME_NAME, BODY_FRAME_NAME, 
            get_a_tform_b, math_helpers
        )
        from bosdyn.client.robot_command import RobotCommandBuilder

        if not detection_result:
            print("[Arm] æ²¡æœ‰æ”¶åˆ°æœ‰æ•ˆç›®æ ‡ï¼Œä¿æŒåŸåœ°å¾…å‘½ã€‚")
            return False

        image_response, pixel_x, pixel_y = detection_result

        if getattr(self, "cmd_client", None) is None or getattr(self, "state_client", None) is None:
            raise RuntimeError("cmd_client/state_client æœªåˆå§‹åŒ–ã€‚")

        try:
            print(f"\n[Arm] æ­£åœ¨è®¡ç®— 3D åæ ‡...")
            
            # --- 1. æå–å†…å‚ ---
            source = image_response.source
            if source.HasField('pinhole'):
                intrinsics = source.pinhole.intrinsics
            elif source.HasField('fisheye'):
                intrinsics = source.fisheye.intrinsics
            else:
                print("[Arm] ä¸æ”¯æŒçš„ç›¸æœºæ¨¡å‹ï¼Œæ— æ³•è½¬æ¢åæ ‡ã€‚")
                return False
                
            fx, fy = intrinsics.focal_length.x, intrinsics.focal_length.y
            cx, cy = intrinsics.principal_point.x, intrinsics.principal_point.y
            
            # --- 2. åƒç´ åæ ‡ -> å±€éƒ¨ 3D å°„çº¿åæ ‡ ---
            x_cam = (pixel_x - cx) / fx
            y_cam = (pixel_y - cy) / fy
            z_cam = 1.0 
            
            length = math.sqrt(x_cam**2 + y_cam**2 + z_cam**2)
            # åœ¨ç›¸æœºåæ ‡ç³»ä¸‹ï¼Œæ ¹æ®å‡è®¾è·ç¦»æ¨ç®—ç‰©ä½“çš„ç¡®åˆ‡ç‚¹
            target_cam = math_helpers.SE3Pose(
                x=(x_cam/length)*assumed_dist, 
                y=(y_cam/length)*assumed_dist, 
                z=(z_cam/length)*assumed_dist, 
                rot=math_helpers.Quat()
            )
            
            # --- 3. è½¬æ¢åˆ°ç»å¯¹ä¸–ç•Œåæ ‡ç³» (VISION) ---
            root_frame = VISION_FRAME_NAME
            cam_frame = image_response.shot.frame_name_image_sensor
            camera_snapshot = image_response.shot.transforms_snapshot
            
            world_T_cam = get_a_tform_b(camera_snapshot, root_frame, cam_frame)
            if world_T_cam is None:
                print(f"[Arm] è‡´å‘½é”™è¯¯ï¼šæ— æ³•æå– {root_frame} åˆ°ç›¸æœºçš„è½¬æ¢ã€‚")
                return False
                
            # è·å–ç›®æ ‡åœ¨ä¸–ç•Œä¸­çš„ç»å¯¹ 3D åæ ‡ (è¿™ä¸ªåæ ‡æ˜¯å›ºå®šçš„ï¼Œå³ä½¿ç‹—åŠ¨äº†ä¹Ÿä¸ä¼šå˜)
            target_world = world_T_cam * target_cam
            
            # =========================================================
            # ç¬¬ä¸€é˜¶æ®µï¼šè½¬åŠ¨ç‹—èº« (Base Control)
            # =========================================================
            print("[Base] å‡†å¤‡è½¬åŠ¨åº•ç›˜é¢æœç›®æ ‡...")
            current_state = self.state_client.get_robot_state()
            world_T_body = get_a_tform_b(current_state.kinematic_state.transforms_snapshot, root_frame, BODY_FRAME_NAME)
            
            # è®¡ç®—ç‹—èº«åˆ°ç›®æ ‡çš„æœå‘ (Yaw)
            dx_body = target_world.x - world_T_body.x
            dy_body = target_world.y - world_T_body.y
            body_yaw = math.atan2(dy_body, dx_body)
            
            # å‘é€åº•ç›˜ç§»åŠ¨æŒ‡ä»¤ï¼šä¿æŒ X, Y ä¸å˜ï¼Œä»…åŸåœ°æ—‹è½¬åˆ°ç›®æ ‡ Yaw
            turn_cmd = RobotCommandBuilder.synchro_se2_trajectory_command(
                goal_x=world_T_body.x,
                goal_y=world_T_body.y,
                goal_heading=body_yaw,
                frame_name=root_frame
            )
            self.cmd_client.robot_command(turn_cmd)
            
            # ç­‰å¾…åº•ç›˜è½¬åŠ¨åˆ°ä½ (è§†å…·ä½“éœ€æ±‚å¯æ”¹ä¸ºè½®è¯¢ feedbackï¼Œè¿™é‡Œç®€å•ç”¨å»¶æ—¶)
            time.sleep(3.0) 
            print(f"[Base] åº•ç›˜å·²è½¬åˆ°ä½ (ç›®æ ‡ Yaw: {math.degrees(body_yaw):.1f}Â°)")

            # =========================================================
            # ç¬¬äºŒé˜¶æ®µï¼šä¼¸å‡ºæ‰‹è‡‚å¹¶æŒ‡å‘ç›®æ ‡ (Arm Control)
            # =========================================================
            print("[Arm] å‡†å¤‡ä¼¸å‡ºæ‰‹è‡‚æŒ‡å‘ç›®æ ‡...")
            # è·å–è½¬åŠ¨èº«ä½“åçš„æœ€æ–°çŠ¶æ€
            new_state = self.state_client.get_robot_state()
            new_world_T_body = get_a_tform_b(new_state.kinematic_state.transforms_snapshot, root_frame, BODY_FRAME_NAME)
            
            # å®šä¹‰ä¸€ä¸ªç›¸å¯¹äºâ€œæ–°èº«ä½“ä½ç½®â€å‘å‰ä¼¸å‡ºçš„æ‰‹éƒ¨é¢„æœŸä½ç½®
            # X: å‘å‰ä¼¸ 0.7m, Y: å±…ä¸­ 0.0m, Z: æŠ¬é«˜ 0.3m (ç›¸å¯¹ body åæ ‡ç³»)
            body_T_extended_hand = math_helpers.SE3Pose(x=0.7, y=0.0, z=0.3, rot=math_helpers.Quat())
            
            # å°†è¿™ä¸ªé¢„æœŸçš„ä¼¸å‡ºæ‰‹éƒ¨ä½ç½®è½¬æ¢å› VISION ä¸–ç•Œåæ ‡ç³»
            world_T_hand_target = new_world_T_body * body_T_extended_hand
            
            # è®¡ç®—ä»è¿™ä¸ªæ–°ä¼¸å‡ºçš„æ‰‹éƒ¨ä½ç½®ï¼ŒæŒ‡å‘ç›®æ ‡çš„ Pitch å’Œ Yaw
            dx_hand = target_world.x - world_T_hand_target.x
            dy_hand = target_world.y - world_T_hand_target.y
            dz_hand = target_world.z - world_T_hand_target.z
            
            arm_yaw = math.atan2(dy_hand, dx_hand)
            dist_xy_hand = math.sqrt(dx_hand**2 + dy_hand**2)
            arm_pitch = math.atan2(-dz_hand, dist_xy_hand) # å‘ä¸‹ä½å¤´ Pitch ä¸ºæ­£
            
            target_rot = math_helpers.Quat.from_yaw(arm_yaw) * math_helpers.Quat.from_pitch(arm_pitch)
            
            # å‘é€æ‰‹è‡‚åŠ¨ä½œæŒ‡ä»¤
            arm_cmd = RobotCommandBuilder.arm_pose_command(
                world_T_hand_target.x, world_T_hand_target.y, world_T_hand_target.z, # ä¼¸å‡ºçš„æ–° XYZ åæ ‡
                target_rot.w, target_rot.x, target_rot.y, target_rot.z, # æŒ‡å‘ç›®æ ‡çš„å››å…ƒæ•°æ—‹è½¬
                root_frame, 
                2.0 # 2.0 ç§’å†…ä¼¸å‡ºå¹¶è½¬åˆ°ä½
            )
            
            self.cmd_client.robot_command(arm_cmd)
            time.sleep(2.5) # ç­‰å¾…æ‰‹è‡‚åŠ¨ä½œå®Œæˆ
            
            print("[Arm] æ‰‹è‡‚å·²ä¼¸å‡ºå¹¶æŒ‡å‘ç›®æ ‡ï¼")
            time.sleep(3)
            return True
            
        except Exception as e:
            print(f"[Arm] æŒ‡å‘ç›®æ ‡å¤±è´¥: {e}")
            return False
    
    def object_register(self, detection_list: list, assumed_dist: float = 1.0) -> list:
        if not detection_list:
            print("[Vision] æœªæ”¶åˆ°æœ‰æ•ˆçš„æ£€æµ‹ç»“æœï¼Œæ¸…é™¤å¹³é¢å›¾ç›®æ ‡ã€‚")
            self._latest_objects = [] # æ¸…é™¤è¿‡æœŸç›®æ ‡
            return []
        registered_objects = []
        print(f"\n[Vision] å¼€å§‹æ‰¹é‡è§£ç®— {len(detection_list)} ä¸ªç›®æ ‡çš„ 3D åæ ‡...")
        for idx, detection in enumerate(detection_list):
            image_response, pixel_x, pixel_y = detection
            try:
                source = image_response.source
                if source.HasField('pinhole'):
                    intrinsics = source.pinhole.intrinsics
                elif source.HasField('fisheye'):
                    intrinsics = source.fisheye.intrinsics
                else:
                    continue
                fx, fy = intrinsics.focal_length.x, intrinsics.focal_length.y
                cx, cy = intrinsics.principal_point.x, intrinsics.principal_point.y
                x_cam = (pixel_x - cx) / fx
                y_cam = (pixel_y - cy) / fy
                z_cam = 1.0 
                length = math.sqrt(x_cam**2 + y_cam**2 + z_cam**2)
                target_cam = math_helpers.SE3Pose(
                    x=(x_cam/length)*assumed_dist, 
                    y=(y_cam/length)*assumed_dist, 
                    z=(z_cam/length)*assumed_dist, 
                    rot=math_helpers.Quat()
                )
                root_frame = "body"
                cam_frame = image_response.shot.frame_name_image_sensor
                camera_snapshot = image_response.shot.transforms_snapshot
                world_T_cam = get_a_tform_b(camera_snapshot, root_frame, cam_frame)
                if world_T_cam is None:
                    continue
                target_world = world_T_cam * target_cam
                print(f"         [ç›®æ ‡ {idx+1}] åæ ‡ç³»: {root_frame} | ä½ç½®: X={target_world.x:.3f}, Y={target_world.y:.3f}, Z={target_world.z:.3f}")
                registered_objects.append({
                    "frame": root_frame,
                    "x": target_world.x,
                    "y": target_world.y,
                    "z": target_world.z,
                    "camera_name": source.name
                })
            except Exception as e:
                print(f"[Vision] âŒ ç›®æ ‡ 3D æ³¨å†Œå¼‚å¸¸: {e}")
        self._latest_objects = registered_objects
        return registered_objects
        
    def grab_first_target(self, detection_list: list) -> bool:
        """
        ä» scan è¿”å›çš„æ£€æµ‹åˆ—è¡¨ä¸­æå–ç¬¬ä¸€ä¸ªç›®æ ‡ï¼Œè‡ªåŠ¨èµ°è¿‡å»å¹¶æŠ“å–ã€‚
        å†…ç½®äº†åº•å±‚ Manipulation API çš„å®Œæ•´æŠ“å–ä¸åé¦ˆè½®è¯¢é€»è¾‘ã€‚
        """
        if not detection_list:
            print("\n[Grab] âš ï¸ æ£€æµ‹åˆ—è¡¨ä¸ºç©ºï¼Œæ²¡æœ‰æ‰¾åˆ°å¯ä»¥æŠ“å–çš„ç›®æ ‡ã€‚")
            return False
        first_target = detection_list[0]
        if isinstance(first_target, dict):
            print("\n[Grab] âŒ æ•°æ®æ ¼å¼é”™è¯¯ï¼è¯·ç¡®ä¿ä¼ å…¥çš„æ˜¯ agent.scan() è¿”å›çš„åŸå§‹åˆ—è¡¨ã€‚")
            return False
        try:
            image_response, pixel_x, pixel_y = first_target[:3]
        except Exception as e:
            print(f"\n[Grab] âŒ è§£æç›®æ ‡æ•°æ®å¤±è´¥: {e}")
            return False
        cam_name = image_response.source.name
        print(f"\n[Grab] ğŸ¯ é”å®šé¦–ä¸ªç›®æ ‡ï¼")
        print(f"       å‘ç°ä½ç½®: {cam_name}")
        print(f"       åƒç´ åæ ‡: ({pixel_x:.1f}, {pixel_y:.1f})")
        print("[Grab] ğŸ• æ­£åœ¨ç§»äº¤åº•å±‚ Manipulation APIï¼ŒSpot å°†è‡ªåŠ¨æ¥è¿‘å¹¶å°è¯•æŠ“å–...")

        # =========================================================
        # æ ¸å¿ƒæŠ“å–ä¸å¯»è·¯é€»è¾‘ (è‡ªåŠ¨èåˆç›¸æœºå¿«ç…§ä¸ 3D é€†è§£ç®—)
        # =========================================================
        if getattr(self, "robot", None) is None:
            print("[Grab] âŒ æœºå™¨äººæœªè¿æ¥æˆ–æœªåˆå§‹åŒ–ã€‚")
            return False

        # åˆå§‹åŒ–æŠ“å–å’ŒæŒ‡ä»¤å®¢æˆ·ç«¯
        manip_client = self.robot.ensure_client(ManipulationApiClient.default_service_name)
        cmd_client = getattr(self, "cmd_client", None) or self.robot.ensure_client(RobotCommandClient.default_service_name)
        self.cmd_client = cmd_client

        # 1. æå–ç›¸æœºæ¨¡å‹å‚æ•° (Pinhole æˆ– Fisheye)
        cam_model = getattr(image_response.source, "pinhole", None) or \
                    getattr(image_response.source, "fisheye", None) or \
                    image_response.source.pinhole

        # 2. æ„å»º 3D æŠ“å–è¯·æ±‚ (PickObjectInImage)
        pick = manipulation_api_pb2.PickObjectInImage(
            pixel_xy=geometry_pb2.Vec2(x=int(pixel_x), y=int(pixel_y)),
            transforms_snapshot_for_camera=image_response.shot.transforms_snapshot,
            frame_name_image_sensor=image_response.shot.frame_name_image_sensor,
            camera_model=cam_model,
        )
        req = manipulation_api_pb2.ManipulationApiRequest(pick_object_in_image=pick)
        
        # 3. å‘é€æŒ‡ä»¤ (æ­¤åˆ»æœºå™¨ç‹—ä¼šè‡ªå·±å¼€å§‹ç®—è·¯å¾„ã€è½¬èº«å¹¶èµ°è¿‡å»)
        print("[Grab] ğŸ“¡ æŠ“å–è¯·æ±‚å·²å‘é€ï¼Œç­‰å¾…æœºå™¨ç‹—è§„åˆ’è·¯å¾„åŠæ‰§è¡ŒåŠ¨ä½œ...")
        rsp = manip_client.manipulation_api_command(manipulation_api_request=req)

        # 4. å¼€å¯è½®è¯¢ï¼Œç›‘æ§ Spot çš„æ‰§è¡ŒçŠ¶æ€
        feedback_timeout_sec = 60.0  # ç•™è¶³è½¬èº«ã€èµ°è·¯å’ŒæŠ“å–çš„æ—¶é—´
        feedback_interval_sec = 0.5
        deadline = time.time() + feedback_timeout_sec
        succeeded = False
        last_name = ""
        
        while time.time() < deadline:
            fb = manip_client.manipulation_api_feedback_command(
                manipulation_api_pb2.ManipulationApiFeedbackRequest(
                    manipulation_cmd_id=rsp.manipulation_cmd_id
                )
            )
            state = fb.current_state
            name = manipulation_api_pb2.ManipulationFeedbackState.Name(state)
            
            # çŠ¶æ€ä¸€æ—¦å‘ç”Ÿå˜åŒ–ï¼Œæ‰“å°å‡ºæ¥ä»¥ä¾¿è°ƒè¯•
            if name != last_name:
                print(f"[Grab] ğŸ”„ çŠ¶æ€æ›´æ–°: {name}")
                last_name = name
                
            if state == manipulation_api_pb2.MANIP_STATE_GRASP_SUCCEEDED:
                succeeded = True
                break
            if state == manipulation_api_pb2.MANIP_STATE_GRASP_FAILED:
                succeeded = False
                break
                
            time.sleep(feedback_interval_sec)

        # =========================================================
        # æŠ“å–å®Œæˆåçš„åŠ¨ä½œåå¤„ç†
        # =========================================================
        if succeeded:
            print("\n[Grab] âœ… æŠ“å–å¤§æˆåŠŸï¼å‡†å¤‡è¿›å…¥æºå¸¦ (Carry) å§¿æ€...")
            try:
                # æŠ“ç´§ç›®æ ‡åï¼ŒæŠŠæ‰‹è‡‚æŠ¬èµ·æ”¶æ‹¢åˆ°èƒ¸å‰ï¼Œé˜²æ­¢èµ°è·¯æ—¶ç¢°åˆ°
                cid = cmd_client.robot_command(RobotCommandBuilder.arm_carry_command())
                block_until_arm_arrives(cmd_client, cid, timeout_sec=6.0)
                time.sleep(0.5)
                print("[Grab] ğŸ¦¾ å·²ç¨³ç¨³æ‹¿ä½ç›®æ ‡ï¼å¤„äº Carry å§¿æ€åŸåœ°å¾…å‘½ã€‚")
            except Exception as e:
                print(f"[Grab] âš ï¸ è½¬æ¢ä¸º Carry å§¿æ€å¤±è´¥: {e}")
        else:
            print("\n[Grab] âŒ æŠ“å–å¤±è´¥ (å¯èƒ½å› ä¸ºç›®æ ‡è¶…å‡ºç‰©ç†å¯è¾¾èŒƒå›´ã€ç›®æ ‡ç§»åŠ¨ï¼Œæˆ–é˜²æ’æœºåˆ¶è§¦å‘)ã€‚")
        return succeeded
    
    # endregion

    # region  Public APIs: Navigation functions
    
    def reset_local_origin(self, frame: str = "vision"):
        from bosdyn.client.frame_helpers import ODOM_FRAME_NAME, VISION_FRAME_NAME, BODY_FRAME_NAME
        state = self.state_client.get_robot_state()
        target_frame = VISION_FRAME_NAME if frame == "vision" else ODOM_FRAME_NAME
        tform = get_a_tform_b(state.kinematic_state.transforms_snapshot, target_frame, BODY_FRAME_NAME)
        self.origin_x = tform.position.x
        self.origin_y = tform.position.y
        self.origin_yaw = self._yaw_from_quat(tform.rotation)
        print(f"[Origin] Local (0,0,0) set to current {frame} pose.")

    def get_home_location(self):
        state = self.state_client.get_robot_state()
        transforms = state.kinematic_state.transforms_snapshot
        vision_tform = get_a_tform_b(transforms, VISION_FRAME_NAME, BODY_FRAME_NAME)
        self.home_x = vision_tform.x
        self.home_y = vision_tform.y
        self.home_yaw = math.degrees(self._yaw_from_quat(vision_tform.rotation))

    def get_guard_location(self):
        state = self.state_client.get_robot_state()
        transforms = state.kinematic_state.transforms_snapshot
        vision_tform = get_a_tform_b(transforms, VISION_FRAME_NAME, BODY_FRAME_NAME)
        self.guard_x = vision_tform.x
        self.guard_y = vision_tform.y
        self.guard_yaw = math.degrees(self._yaw_from_quat(vision_tform.rotation))

    # endregion

    # region  Public APIs: Debug tools

    def debug_pose(self):
        state = self.state_client.get_robot_state()
        transforms = state.kinematic_state.transforms_snapshot
        vision_tform = get_a_tform_b(transforms, VISION_FRAME_NAME, BODY_FRAME_NAME)
        print(f"\n--- SDK [VISION] Frame ---")
        print(f"X: {vision_tform.x:.4f}, Y: {vision_tform.y:.4f}")
        print(f"Yaw: {math.degrees(self._yaw_from_quat(vision_tform.rotation)):.2f}Â°")
        print("="*30 + "\n")   

    # endregion 
    
    def grab_target_with_nav(self, detector, detection_list: list) -> bool:
        """
        å¼•å…¥ä¸¤æ®µå¼æŠ“å–é€»è¾‘ï¼š
        1. ç²—å®šä½ï¼šè§£ç®—ç›®æ ‡çš„ç»å¯¹ 3D åæ ‡
        2. å¯»è·¯å¯¹é½ï¼šè®¡ç®—é¢„æŠ“å–ç‚¹ï¼ˆè·ç¦»ç›®æ ‡å‰æ–¹çº¦ 0.65 ç±³ï¼‰ï¼Œè°ƒç”¨ move_to_goal èµ°è¿‡å»
        3. å§¿æ€å‡†å¤‡ï¼šæ§åˆ¶æœºæ¢°è‡‚å‰ä¼¸å¹¶ä½å¤´ï¼Œä¿¯è§†ç›®æ ‡å¯èƒ½å­˜åœ¨çš„åŒºåŸŸ (æ–°å¢)
        4. ç²¾ç¡®å®šä½ï¼šä½¿ç”¨æ‰‹éƒ¨ç›¸æœºé‡æ–°æ‰«æï¼Œç¡®ä¿åœ¨æ­£å‰æ–¹æ— æ­»è§’
        5. å‡ºçˆªï¼šåŸºäºæ–°ç”»é¢æ‰§è¡Œç²¾å‡†æŠ“å–
        """
        import time
        import math
        import numpy as np
        import cv2
        from bosdyn.client.frame_helpers import get_a_tform_b, VISION_FRAME_NAME, GRAV_ALIGNED_BODY_FRAME_NAME, math_helpers
        from bosdyn.client.robot_state import RobotStateClient
        from bosdyn.client.image import build_image_request
        from bosdyn.client.math_helpers import SE3Pose, Quat
        from bosdyn.client.robot_command import RobotCommandBuilder

        if not detection_list:
            print("\n[NavGrab] âš ï¸ æ£€æµ‹åˆ—è¡¨ä¸ºç©ºã€‚")
            return False

        first_target = detection_list[0]
        try:
            image_response, pixel_x, pixel_y = first_target[:3]
        except Exception as e:
            print(f"\n[NavGrab] âŒ æ•°æ®è§£æå¤±è´¥: {e}")
            return False

        # ==========================================
        # 1. ç²—å®šä½ï¼šè§£ç®—å¤§è‡´çš„ç»å¯¹ 3D ä¸–ç•Œåæ ‡
        # ==========================================
        source = image_response.source
        cam_model = getattr(source, "pinhole", None) or getattr(source, "fisheye", None) or source.pinhole
        intrinsics = cam_model.intrinsics
        
        fx, fy = intrinsics.focal_length.x, intrinsics.focal_length.y
        cx, cy = intrinsics.principal_point.x, intrinsics.principal_point.y
        
        x_cam = (pixel_x - cx) / fx
        y_cam = (pixel_y - cy) / fy
        z_cam = 1.0 
        length = math.sqrt(x_cam**2 + y_cam**2 + z_cam**2)
        
        # å®‰å…¨è®¾å®šï¼šé¢„ä¼°ç›®æ ‡è·ç¦»è®¾ä¸º 0.8 ç±³
        assumed_dist = 0.8  
        target_cam = SE3Pose(
            x=(x_cam/length)*assumed_dist, 
            y=(y_cam/length)*assumed_dist, 
            z=(z_cam/length)*assumed_dist, 
            rot=Quat()
        )
                             
        root_frame = VISION_FRAME_NAME
        cam_frame = image_response.shot.frame_name_image_sensor
        camera_snapshot = image_response.shot.transforms_snapshot
        
        world_T_cam = get_a_tform_b(camera_snapshot, root_frame, cam_frame)
        target_world = world_T_cam * target_cam
        obj_x, obj_y = target_world.x, target_world.y

        # ==========================================
        # 2. å¯»è·¯å¯¹é½ï¼šè®¡ç®—æœ€ä½³æŠ“å–èº«ä½å¹¶èµ°è¿‡å»
        # ==========================================
        state_client = self.robot.ensure_client(RobotStateClient.default_service_name)
        rs = state_client.get_robot_state()
        tf = rs.kinematic_state.transforms_snapshot
        world_T_body = get_a_tform_b(tf, root_frame, "body")
        rob_x, rob_y = world_T_body.position.x, world_T_body.position.y
        
        dx = obj_x - rob_x
        dy = obj_y - rob_y
        dist = math.hypot(dx, dy)
        angle = math.atan2(dy, dx)
        
        standoff_dist = 0.65  # æœºå™¨ç‹—åœåœ¨è·ç¦»ç›®æ ‡ 0.65 ç±³çš„åœ°æ–¹å‡ºçˆªæœ€èˆ’æœ
        
        if dist > standoff_dist:
            nav_x = obj_x - standoff_dist * math.cos(angle)
            nav_y = obj_y - standoff_dist * math.sin(angle)
        else:
            nav_x, nav_y = rob_x, rob_y
            
        nav_yaw_deg = math.degrees(angle)
        
        print(f"\n[NavGrab] ğŸ§­ ç›®æ ‡å¤§è‡´ä½ç½®æ¨ç®—: X={obj_x:.2f}, Y={obj_y:.2f}")
        print(f"[NavGrab] ğŸš¶ æ­£åœ¨å‰å¾€é¢„å¤‡æŠ“å–ç‚¹: X={nav_x:.2f}, Y={nav_y:.2f}, è½¬èº«å¯¹é½è§’åº¦={nav_yaw_deg:.1f}Â°")
        
        self.move_to_goal(x=nav_x, y=nav_y, angle_deg=nav_yaw_deg, frame="vision", use_local_origin=False)
        
        print("[NavGrab] â³ ç­‰å¾…ç§»åŠ¨åˆ°ä½ (8ç§’)...")
        time.sleep(8.0)

        # ==========================================
        # 3. å§¿æ€å‡†å¤‡ï¼šæ§åˆ¶æœºæ¢°è‡‚ä½å¤´çœ‹å‘æŠ“å–ç‚¹ (æ–°å¢é€»è¾‘)
        # ==========================================
        print("\n[NavGrab] ğŸ¦¾ æ­£åœ¨è°ƒæ•´æœºæ¢°è‡‚å§¿æ€ï¼Œä½å¤´ä¿¯è§†é¢„æŠ“å–åŒºåŸŸ...")
        try:
            # æ‰‹éƒ¨æ”¾åœ¨èº«ä½“æ­£å‰æ–¹ 0.35ç±³ï¼Œé«˜åº¦ 0.1ç±³ï¼Œå¹¶å‘ä¸‹ä½å¤´ 45 åº¦
            pitch_deg = 45.0
            q_pitch = math_helpers.Quat.from_pitch(math.radians(pitch_deg))
            
            look_down_cmd = RobotCommandBuilder.arm_pose_command(
                x=0.35, y=0.0, z=0.1, 
                qw=q_pitch.w, qx=q_pitch.x, qy=q_pitch.y, qz=q_pitch.z, 
                frame_name=GRAV_ALIGNED_BODY_FRAME_NAME, 
                seconds=2.0
            )
            self.cmd_client.robot_command(look_down_cmd)
            time.sleep(2.5) # ç­‰å¾…æ‰‹è‡‚ç§»åŠ¨å¹³ç¨³ï¼Œé˜²æ­¢ç”»é¢æ¨¡ç³Š
        except Exception as e:
            print(f"[NavGrab] âš ï¸ è°ƒæ•´æœºæ¢°è‡‚å§¿æ€å¤±è´¥: {e}")

        # ==========================================
        # 4. ç²¾ç¡®å®šä½ï¼šç§»åŠ¨å’Œä½å¤´åï¼Œé‡æ–°æ‹ç…§è·å–æœ€æ–°å¿«ç…§
        # ==========================================
        print("\n[NavGrab] ğŸ“¸ å§¿æ€è°ƒæ•´å®Œæ¯•ï¼Œæ­£åœ¨ä½¿ç”¨æ‰‹éƒ¨(æ­£å‰)ç›¸æœºé‡æ–°è¿›è¡Œç²¾ç¡®é”å®š...")
        image_client = self.robot.ensure_client('image')
        req = build_image_request('hand_color_image', quality_percent=70)
        
        try:
            res = image_client.get_image([req])[0]
            if res.status != image_pb2.ImageResponse.STATUS_OK:
                print("[NavGrab] âŒ è·å–æ‰‹éƒ¨å›¾åƒå¤±è´¥ã€‚")
                return False
                
            img_np = np.frombuffer(res.shot.image.data, dtype=np.uint8)
            img = cv2.imdecode(img_np, cv2.IMREAD_COLOR)
            
            # ä½¿ç”¨ä¼ è¿›æ¥çš„ YOLO æ£€æµ‹å™¨é‡æ–°æ‰«ä¸€çœ¼è¿™å¼ æ–°å›¾
            results = detector.detect_targets_in_batch({'hand_color_image': img}, conf=0.05)
            
            if not results:
                print("[NavGrab] âŒ èµ°è¿‘ä½å¤´åä¸¢å¤±ç›®æ ‡ï¼(å¯èƒ½è¢«è¸¢é£æˆ–åœ¨è§†é‡è¾¹ç¼˜)")
                return False
                
            best = results[0]
            new_x, new_y = best['cx'], best['cy']
            print(f"[NavGrab] ğŸ¯ å®Œç¾ï¼å·²åœ¨æ­£å‰æ–¹é‡æ–°é”å®šç›®æ ‡ï¼Œæ–°åƒç´ : ({new_x}, {new_y})")
            
            # 5. åŸºäºå…¨æ–°çš„ç…§ç‰‡å’Œåƒç´ å‡ºçˆªï¼
            return self._execute_grasp(res, new_x, new_y)
            
        except Exception as e:
            print(f"[NavGrab] âš ï¸ é‡å®šä½é˜¶æ®µå‘ç”Ÿå¼‚å¸¸: {e}")
            return False

    def _execute_grasp(self, image_response, pixel_x, pixel_y) -> bool:
        """ å†…éƒ¨ä¸“ç”¨å‡½æ•°ï¼šä»…è´Ÿè´£å‘é€ Manipulation æŠ“å–è¯·æ±‚å¹¶è½®è¯¢çŠ¶æ€ """
        import time
        from bosdyn.api import geometry_pb2, manipulation_api_pb2
        from bosdyn.client.manipulation_api_client import ManipulationApiClient
        from bosdyn.client.robot_command import RobotCommandClient, RobotCommandBuilder, block_until_arm_arrives

        print("[Grab] ğŸ• ç§»äº¤åº•å±‚æœºæ¢°è‡‚ APIï¼Œå¼€å§‹è®¡ç®— IK å¹¶æŠ“å–...")
        manip_client = self.robot.ensure_client(ManipulationApiClient.default_service_name)
        cmd_client = getattr(self, "cmd_client", None) or self.robot.ensure_client(RobotCommandClient.default_service_name)
        self.cmd_client = cmd_client

        cam_model = getattr(image_response.source, "pinhole", None) or \
                    getattr(image_response.source, "fisheye", None) or \
                    image_response.source.pinhole

        pick = manipulation_api_pb2.PickObjectInImage(
            pixel_xy=geometry_pb2.Vec2(x=int(pixel_x), y=int(pixel_y)),
            transforms_snapshot_for_camera=image_response.shot.transforms_snapshot,
            frame_name_image_sensor=image_response.shot.frame_name_image_sensor,
            camera_model=cam_model,
        )
        req = manipulation_api_pb2.ManipulationApiRequest(pick_object_in_image=pick)
        rsp = manip_client.manipulation_api_command(manipulation_api_request=req)

        deadline = time.time() + 30.0
        succeeded = False
        last_name = ""
        
        while time.time() < deadline:
            fb = manip_client.manipulation_api_feedback_command(
                manipulation_api_pb2.ManipulationApiFeedbackRequest(
                    manipulation_cmd_id=rsp.manipulation_cmd_id
                )
            )
            state = fb.current_state
            name = manipulation_api_pb2.ManipulationFeedbackState.Name(state)
            if name != last_name:
                print(f"       ğŸ”„ åŠ¨ä½œçŠ¶æ€: {name}")
                last_name = name
                
            if state == manipulation_api_pb2.MANIP_STATE_GRASP_SUCCEEDED:
                succeeded = True
                break
            if state == manipulation_api_pb2.MANIP_STATE_GRASP_FAILED:
                succeeded = False
                break
            time.sleep(0.5)

        if succeeded:
            print("\n[Grab] âœ… æŠ“å–å¤§æˆåŠŸï¼æ”¶æ‹¢æ‰‹è‡‚è¿›å…¥ Carry å§¿æ€...")
            try:
                cid = cmd_client.robot_command(RobotCommandBuilder.arm_carry_command())
                block_until_arm_arrives(cmd_client, cid, timeout_sec=6.0)
                time.sleep(0.5)
            except Exception:
                pass
        else:
            print("\n[Grab] âŒ æŠ“å–å¤±è´¥ã€‚")

        return succeeded
